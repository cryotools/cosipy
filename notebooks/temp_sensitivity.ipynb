{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "psychological-anderson",
   "metadata": {},
   "source": [
    "# Input data and temperature sensitivity\n",
    "\n",
    "A continuation of the simple sensitivity study we did in \n",
    "[Sensitivity studies using COSIPY](sensitivity_study.ipynb) is to investigate how changing the surface temperature, or any other input variable, affects the calculation of the surface mass balance. COSIPY reads the meteorological input data from a **netcdf** file during the run. This means that during each time step the model reads the meteorological data from the corresponding time step in the input file. The input file can be either \"1D\" for a point simulation or \"2D\" for a distributed simulation. The input file can be based on either observed or modeled data.\n",
    "\n",
    "In order to conduct the temperature sensitivity study (or any study) from scratch we need to do the following:\n",
    "- Create the input file from observations.\n",
    "- Load the input file into a xarray dataset.\n",
    "- Create copies of this dataset and add the bias to the variable in question.\n",
    "\n",
    "With this done we can run the simulations. But before we do any of this, we can take a look at the input data for the Zhadang glacier, which is shipped with COSPIY for theses tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-agreement",
   "metadata": {},
   "source": [
    "**The standard imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to change the cwd for the ipython session, otherwise COSIPY\n",
    "# will look for things in the wrong places.\n",
    "import os\n",
    "import sys\n",
    "# This is not really a good method, if cell is re run we end up in the\n",
    "# wrong directory.\n",
    "os.chdir('./../')\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosipy.utils import edu_utils\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to tell matplotlib to plot inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-slovenia",
   "metadata": {},
   "source": [
    "The path to the input netcdf is stored in the `input_netcdf` variable. We can take a look at the options for the current value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print options returns a pandas dataframe with the variable as the index,\n",
    "# hence we can index it.\n",
    "edu_utils.print_options().loc['input_netcdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-director",
   "metadata": {},
   "source": [
    "We can then open the file with xarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files are located in ./data/ relative to the root directory of cosipy. \n",
    "# This is also our current working directory.\n",
    "input_path = './data/' + 'input/' +\\\n",
    "            edu_utils.OPTIONS['input_netcdf']\n",
    "with xr.open_dataset(input_path) as ds:\n",
    "    ds = ds.isel(time=slice(0, -1)).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-alarm",
   "metadata": {},
   "source": [
    "As you can see, this file contain variables such as the 2-meter temperature (T2), the relative humidity at 2 meters (RH2) and the cloud cover (N) for one single point. The time coordinate spans 2009-01-01 00:00:00 and 2009-01-31 22:00:00 at a hourly resolution.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<details>\n",
    "    <summary><b>Question: Can you figure out what the variable G is and what unit it has?</b> <i>Click me for a hint!</i></summary>\n",
    "    Try pressing the document symbol to the right in the output above, this shows some extra information about the variable.\n",
    "    </details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-development",
   "metadata": {},
   "source": [
    "We can quickly take a look at one of the variables by plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.T2.plot(figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-expert",
   "metadata": {},
   "source": [
    "## Creating the input files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-newton",
   "metadata": {},
   "source": [
    "In this case COSIPY comes packaged with the processed data which can directly be used to drive a simulation. In a more realistic scenario however, you probably want drive COSIPY with your own data from another glacier than the Zhadang glacier. The `aws2cosipy` module is provided by COSIPY to aid the processing of .csv-files from weather stations or nwp-output into input files which can be used by COSIPY. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the create_1D_input function to process a single point\n",
    "from utilities.aws2cosipy.aws2cosipy import create_1D_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-rogers",
   "metadata": {},
   "source": [
    "The `create_1D_input` has five arguments: the csv file to process, the name of the resulting input file, the name of a static file describing the altitude, slope and aspect of the grid point, and the start and end date.\n",
    "\n",
    "In our case the .csv file is located in the same directory as the input file we looked at earlier. It is called `Zhadang_ERA5_2009_2018.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the file\n",
    "file = './data/input/Zhadang/Zhadang_ERA5_2009_2018.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static file\n",
    "static_file = './data/static/Zhadang_static.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time start and end.\n",
    "start_date = '20120701'\n",
    "end_date = '20120731'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output file, we change this for our year.\n",
    "output_name = './data/input/Zhadang/Zhadang_ERA5_2012_test.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function, this takes some time.\n",
    "create_1D_input(file, output_name, static_file, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-carpet",
   "metadata": {},
   "source": [
    "Open the file to see that it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(output_name) as ds:\n",
    "    ds = ds.isel(time=slice(0, -1)).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-pottery",
   "metadata": {},
   "source": [
    "This created a input file with data for the month of July in 2012. The .csv-file contains data from January 2000 until early January 2018, so you are free to change the start and end data accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-correction",
   "metadata": {},
   "source": [
    "## Creating datasets for temperature bias experiments\n",
    "\n",
    "A temperature bias experiment is essentially a sensitivity study. It explores the effects of changing the temperature by $n$ degrees over the whole time period. For example, let's say we want to know how the glacier responds to a climate which is  2 Â°C warmer. This approach isolates the effect of temperature on the glacier and does not take other factors, like a changing hydrological cycle, into account.\n",
    "\n",
    "Setting this up with COSIPY follows a similar approach as described in the [Sensitivity studies with COSIPY](sensitivity_study.ipynb). However, instead of manipulating the the constants of the model with the `opt_dict` we are changing the dataset containing the input data before sending it to the `cosipy_core`.\n",
    "\n",
    "If we want to use our newly processed input file, we have to change the `input_netcdf` in the `opt_dict` along with the integration time (`time_start` & `time_end`) since this have to match the data. After this we can initiate the IOClass and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dict = {'input_netcdf': 'Zhadang/Zhadang_ERA5_2012_test.nc',\n",
    "            'time_start': '2012-07-01T00:00',\n",
    "            'time_end': '2012-07-31T00:00'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default\n",
    "IO_def, DATA_def, RESULTS_def = edu_utils.create_IO(opt_dict)\n",
    "# Up\n",
    "IO_up, DATA_up, RESULTS_up = edu_utils.create_IO(opt_dict)\n",
    "# Down\n",
    "IO_dn, DATA_dn, RESULTS_dn = edu_utils.create_IO(opt_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-pleasure",
   "metadata": {},
   "source": [
    "And then apply the bias to the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias is two degrees\n",
    "bias = 2\n",
    "DATA_dn['T2'] = DATA_dn['T2'] - bias\n",
    "DATA_up['T2'] = DATA_up['T2'] + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-henry",
   "metadata": {},
   "source": [
    "**Plot it to make sure it worked**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "DATA_def['T2'].plot(ax=ax, label='Default')\n",
    "DATA_up['T2'].plot(ax=ax, label='+2')\n",
    "DATA_dn['T2'].plot(ax=ax, label='-2')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-president",
   "metadata": {},
   "source": [
    "### Setting up the run\n",
    "As in the previous sensitivity study we put everything in a list of lists. Note that we're not  any of the options this time, only the input data and results dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of lists with our experiments\n",
    "exp_list = [[DATA_def, IO_def, RESULTS_def],\n",
    "            [DATA_dn, IO_dn, RESULTS_dn],\n",
    "            [DATA_up, IO_up, RESULTS_up]\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-disorder",
   "metadata": {},
   "source": [
    "And lets runs the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in exp_list:\n",
    "    # Call run_model once for each experiment\n",
    "    edu_utils.run_model(DATA=exp[0], IO=exp[1], RESULT=exp[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-project",
   "metadata": {},
   "source": [
    "We select a few days in the middle of the month to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Default', '-2$\\degree$C', '+2$\\degree$C']\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for exp, label in zip(exp_list, labels):\n",
    "    # Get the data and plot it RESULTS are kept at the third spot, index 2\n",
    "    exp[2].sel(time=slice('2012-07-07', '2012-07-12')).surfMB.plot(ax=ax,\n",
    "                                                                   label=label)\n",
    "plt.legend(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-recipe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <details>\n",
    "        <summary>\n",
    "            <b>Question: What is the difference between the experiments in the total mass lost during the period plotted above?</b> <i>Click me for an explanation</i>\n",
    "        </summary>\n",
    "        Try selecting the data from the experiment list and then calculate the sum with .sum(). Alternatively you can also copy the cell above and add .cumsum() before .plot(). This will plot the cumulative sum over the period.\n",
    "    </details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can write some code. Click to open.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-inflation",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "[Back to overview](welcome.ipynb)\n",
    "\n",
    "[Distributed simulations](distributed_run.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosipy",
   "language": "python",
   "name": "cosipy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
