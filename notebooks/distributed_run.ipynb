{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mathematical-travel",
   "metadata": {},
   "source": [
    "# A first distributed simulation\n",
    "\n",
    "Until now, we've only been working with single grid point simulations. This is fine for learning and playing around with different configurations of the model since the runs takes less time. A more typical use case of COSIPY is to run a distributed simulation over the entire surface of the glacier, which gives us a much more detailed view of the glacier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to change the cwd for the ipython session, otherwise COSIPY\n",
    "# will look for things in the wrong places.\n",
    "import os\n",
    "import sys\n",
    "# This is not really a good method, if cell is re run we end up in the\n",
    "# wrong directory.\n",
    "os.chdir('./../')\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosipy.utils import edu_utils\n",
    "# cfg gives us the NAMELIST\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to tell matplotlib to plot inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-program",
   "metadata": {},
   "source": [
    "Setting up a distributed simulation is fairly easy. All we need is 2D input data (3D with time). This data could either be in the form of gcm/reanalysis output or interpolated from station data. For the tutorials we provide a distributed input file `Zhadang_ERA5_2009_dst.nc` for Zhadang. We can take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where the data is located.\n",
    "input_path = './data/input/'\n",
    "with xr.open_dataset(input_path+'Zhadang/Zhadang_ERA5_2009_dst.nc') as ds:\n",
    "    ds = ds.isel(time=slice(0, -1)).load()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-whale",
   "metadata": {},
   "source": [
    "The input data contains 91 gridpoints. However, only 17 of these are actually within the glacier boundaries and are used for the run. This input data also covers the whole of 2009, so lets also set up the run for a summer month.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <details>\n",
    "        <Summary> <b>Where is the information about the number gridpoints within the glacier?</b> <i>Click me for a hint</i></Summary>\n",
    "        The points within the glacier are selected based on the MASK variable. You can plot it or \"show\" the data by pressing the storage symbol in the output above. It also possible to count it with the method .count(). Try it below!\n",
    "    </details>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for the reader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-homeless",
   "metadata": {},
   "source": [
    "## Running a distributed simulation\n",
    "\n",
    "Now that we've confirmed that the data is of the right dimension, we can initialize the datasets needed to run the simulation. First we have to add the new input file in the `opt_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The print_options returns a pandas dataframe so we can index it.\n",
    "edu_utils.print_options().loc['input_netcdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_dict\n",
    "opt_dict = dict()\n",
    "# We change the input_netcdf\n",
    "opt_dict['input_netcdf'] = 'Zhadang/Zhadang_ERA5_2009_dst.nc'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-manor",
   "metadata": {},
   "source": [
    "And lets change the start and end dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_utils.print_options().loc['time_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dict['time_start'] = '2009-07-01T00:00'\n",
    "opt_dict['time_end'] = '2009-07-31T00:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-advantage",
   "metadata": {},
   "source": [
    "With this done we can initialize the datasets needed for running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "IO, DATA, RESULTS = edu_utils.create_IO(opt_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-anthropology",
   "metadata": {},
   "source": [
    "The output above confirms that we have 17 glacier gridpoints in our input data.\n",
    "\n",
    "## Running the model\n",
    "We are now ready to run the model. This is just as simple as in the one dimensional case. In the background the results of each gridpoint is calculated individually, we're basically stacking multiple point simulations next to each other. The `edu_utils.run_model` distributes the work so that gridpoints are executed in parallel. Note however that this still might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_utils.run_model(DATA, IO, RESULTS, opt_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-shadow",
   "metadata": {},
   "source": [
    "As before we can take a quick look at the results. First however, we have to reduce the dimensions of the data. A simple way is to select a single time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS.isel(time=1).MB.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-consortium",
   "metadata": {},
   "source": [
    "Alternatively we can also reduce one of the dimensions by taking the mean of it, creating a so called Hovm√∂ller diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS.MB.mean(dim='lon').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-madagascar",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "[Back to overview](welcome.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosipy",
   "language": "python",
   "name": "cosipy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
